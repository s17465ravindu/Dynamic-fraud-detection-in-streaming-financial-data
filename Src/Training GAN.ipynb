{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.combine import SMOTETomek,SMOTEENN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import set_start_method\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Uni Docs\\DSC4996\\Dynamic_fraud_detection_system\\Data\\pre_processed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_trans = df[df['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278813</th>\n",
       "      <td>169142.0</td>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279090</th>\n",
       "      <td>169347.0</td>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279096</th>\n",
       "      <td>169351.0</td>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280081</th>\n",
       "      <td>169966.0</td>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280611</th>\n",
       "      <td>170348.0</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "534        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "616        472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4886      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6072      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6293      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "278813  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
       "279090  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
       "279096  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
       "280081  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
       "280611  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "534    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "616     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4886    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6072   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6293    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "278813 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
       "279090 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
       "279096 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
       "280081 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
       "280611  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "534     0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "616    -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4886   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6072   -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6293   -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "278813 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "279090 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "279096  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "280081 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "280611 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[473 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE GAN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "BATCH_SIZE=1000\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS=0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_trans = fraud_trans.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditCardData(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = torch.tensor(self.data.iloc[index]).float()\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data: pd.DataFrame, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Empty prepare_data method left in intentionally. \n",
    "        https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html#prepare-data\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        train_df, test_df = train_test_split(self.data, random_state=123, test_size=0.2)\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        data_mean = train_df.mean()\n",
    "        data_std = train_df.std()\n",
    "        train_norm = (train_df - data_mean)/data_std\n",
    "        test_norm = (test_df - data_mean)/data_std\n",
    "        self.train_df = train_norm\n",
    "        self.test_df = test_norm\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=CreditCardData(self.train_df), batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    \n",
    "    def valid_dataloader(self):\n",
    "        return DataLoader(CreditCardData(self.val_df), batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(CreditCardData(self.test_df), batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 100),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(100, 80),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(80, 40),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(40, 30)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.sequential(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(30, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tensor = torch.sigmoid(self.sequential(x))\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self, latent_dim=100, lr=0.002):\n",
    "        super().__init__()\n",
    "        self.automatic_optimization = False\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.generator = Generator(latent_dim = self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        self.validation_z = torch.randn(6, self.hparams.latent_dim)\n",
    "        \n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch ): \n",
    "        real_data = batch\n",
    "        \n",
    "        opt_1, opt_2 = self.optimizers()\n",
    "        z = torch.randn(real_data.size(0), self.hparams.latent_dim)\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr )\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr )\n",
    "        return [opt_g, opt_d], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 22.7 K\n",
      "1 | discriminator | Discriminator | 13.5 K\n",
      "------------------------------------------------\n",
      "36.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.2 K    Total params\n",
      "0.145     Total estimated model params size (MB)\n",
      "c:\\Users\\Ravin\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Ravin\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1e8008eae24c9daf79fcc5b83b300a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(fraud_trans)\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(gnn, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1255, -0.0655,  0.1160,  ..., -0.0322, -0.1999, -0.1380],\n",
       "        [-0.1705, -0.0180,  0.0969,  ..., -0.0784, -0.1806, -0.0667],\n",
       "        [-0.1942, -0.0403,  0.0915,  ..., -0.0915, -0.2061, -0.1551],\n",
       "        ...,\n",
       "        [-0.1367,  0.0287,  0.1145,  ...,  0.0078, -0.1930, -0.0721],\n",
       "        [-0.0970,  0.0323,  0.0931,  ..., -0.0442, -0.2048, -0.1104],\n",
       "        [-0.1208,  0.0729,  0.2215,  ..., -0.0819, -0.2145, -0.0130]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(85000, 100)\n",
    "output = gnn(z)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_fraud_df =  pd.DataFrame(output.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_fraud_df['Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.125472</td>\n",
       "      <td>-0.065518</td>\n",
       "      <td>0.116015</td>\n",
       "      <td>-0.078386</td>\n",
       "      <td>-0.070315</td>\n",
       "      <td>-0.122219</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>-0.126982</td>\n",
       "      <td>0.037647</td>\n",
       "      <td>-0.064911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093300</td>\n",
       "      <td>-0.030247</td>\n",
       "      <td>0.125862</td>\n",
       "      <td>-0.075998</td>\n",
       "      <td>-0.203211</td>\n",
       "      <td>-0.113421</td>\n",
       "      <td>-0.032202</td>\n",
       "      <td>-0.199925</td>\n",
       "      <td>-0.137983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170451</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>0.096852</td>\n",
       "      <td>-0.065626</td>\n",
       "      <td>0.072934</td>\n",
       "      <td>-0.109999</td>\n",
       "      <td>0.105688</td>\n",
       "      <td>-0.139326</td>\n",
       "      <td>-0.024676</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>-0.029055</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>-0.035170</td>\n",
       "      <td>-0.226974</td>\n",
       "      <td>-0.050105</td>\n",
       "      <td>-0.078412</td>\n",
       "      <td>-0.180631</td>\n",
       "      <td>-0.066747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.194220</td>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>-0.017461</td>\n",
       "      <td>-0.019851</td>\n",
       "      <td>-0.126800</td>\n",
       "      <td>0.100452</td>\n",
       "      <td>-0.153539</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>-0.032416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144041</td>\n",
       "      <td>0.039883</td>\n",
       "      <td>0.146865</td>\n",
       "      <td>-0.086697</td>\n",
       "      <td>-0.240962</td>\n",
       "      <td>-0.144000</td>\n",
       "      <td>-0.091510</td>\n",
       "      <td>-0.206072</td>\n",
       "      <td>-0.155127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093280</td>\n",
       "      <td>-0.046098</td>\n",
       "      <td>0.146738</td>\n",
       "      <td>-0.053210</td>\n",
       "      <td>0.109236</td>\n",
       "      <td>-0.054069</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>-0.196522</td>\n",
       "      <td>-0.041214</td>\n",
       "      <td>-0.055622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050068</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.022157</td>\n",
       "      <td>-0.161324</td>\n",
       "      <td>-0.015622</td>\n",
       "      <td>-0.043951</td>\n",
       "      <td>-0.208535</td>\n",
       "      <td>-0.073233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.150356</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>0.128281</td>\n",
       "      <td>-0.067569</td>\n",
       "      <td>0.016128</td>\n",
       "      <td>-0.088675</td>\n",
       "      <td>0.093983</td>\n",
       "      <td>-0.178635</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>-0.070727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137437</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.095065</td>\n",
       "      <td>-0.012209</td>\n",
       "      <td>-0.176238</td>\n",
       "      <td>-0.080777</td>\n",
       "      <td>-0.105282</td>\n",
       "      <td>-0.187900</td>\n",
       "      <td>-0.072092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84995</th>\n",
       "      <td>-0.150924</td>\n",
       "      <td>-0.038800</td>\n",
       "      <td>0.121220</td>\n",
       "      <td>-0.064548</td>\n",
       "      <td>0.079419</td>\n",
       "      <td>-0.093290</td>\n",
       "      <td>0.068619</td>\n",
       "      <td>-0.164228</td>\n",
       "      <td>-0.042417</td>\n",
       "      <td>-0.022502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>0.067957</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>-0.259302</td>\n",
       "      <td>-0.084166</td>\n",
       "      <td>-0.045353</td>\n",
       "      <td>-0.170909</td>\n",
       "      <td>-0.087426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84996</th>\n",
       "      <td>-0.106713</td>\n",
       "      <td>-0.055724</td>\n",
       "      <td>0.107255</td>\n",
       "      <td>-0.058044</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>-0.121099</td>\n",
       "      <td>0.060768</td>\n",
       "      <td>-0.122340</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054211</td>\n",
       "      <td>0.055740</td>\n",
       "      <td>0.093475</td>\n",
       "      <td>-0.059595</td>\n",
       "      <td>-0.205103</td>\n",
       "      <td>-0.044279</td>\n",
       "      <td>-0.103343</td>\n",
       "      <td>-0.192009</td>\n",
       "      <td>-0.081781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84997</th>\n",
       "      <td>-0.136717</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>0.114541</td>\n",
       "      <td>-0.098674</td>\n",
       "      <td>0.067010</td>\n",
       "      <td>-0.102722</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>-0.141780</td>\n",
       "      <td>-0.035653</td>\n",
       "      <td>-0.068010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035877</td>\n",
       "      <td>-0.030915</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>-0.060992</td>\n",
       "      <td>-0.183590</td>\n",
       "      <td>-0.083636</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>-0.193032</td>\n",
       "      <td>-0.072074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84998</th>\n",
       "      <td>-0.096986</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.093093</td>\n",
       "      <td>-0.066559</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.098856</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>-0.115086</td>\n",
       "      <td>-0.062757</td>\n",
       "      <td>-0.078121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079448</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.111139</td>\n",
       "      <td>-0.063026</td>\n",
       "      <td>-0.132691</td>\n",
       "      <td>-0.121015</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>-0.204784</td>\n",
       "      <td>-0.110402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84999</th>\n",
       "      <td>-0.120800</td>\n",
       "      <td>0.072861</td>\n",
       "      <td>0.221468</td>\n",
       "      <td>0.043496</td>\n",
       "      <td>0.066387</td>\n",
       "      <td>-0.064045</td>\n",
       "      <td>-0.013091</td>\n",
       "      <td>-0.148051</td>\n",
       "      <td>-0.089153</td>\n",
       "      <td>-0.073449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090129</td>\n",
       "      <td>0.077935</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>-0.052842</td>\n",
       "      <td>-0.055504</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>-0.081928</td>\n",
       "      <td>-0.214467</td>\n",
       "      <td>-0.013046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.125472 -0.065518  0.116015 -0.078386 -0.070315 -0.122219  0.017378   \n",
       "1     -0.170451 -0.018026  0.096852 -0.065626  0.072934 -0.109999  0.105688   \n",
       "2     -0.194220 -0.040289  0.091481 -0.017461 -0.019851 -0.126800  0.100452   \n",
       "3     -0.093280 -0.046098  0.146738 -0.053210  0.109236 -0.054069  0.056616   \n",
       "4     -0.150356 -0.012215  0.128281 -0.067569  0.016128 -0.088675  0.093983   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "84995 -0.150924 -0.038800  0.121220 -0.064548  0.079419 -0.093290  0.068619   \n",
       "84996 -0.106713 -0.055724  0.107255 -0.058044  0.025893 -0.121099  0.060768   \n",
       "84997 -0.136717  0.028664  0.114541 -0.098674  0.067010 -0.102722  0.023048   \n",
       "84998 -0.096986  0.032258  0.093093 -0.066559  0.066235 -0.098856  0.037679   \n",
       "84999 -0.120800  0.072861  0.221468  0.043496  0.066387 -0.064045 -0.013091   \n",
       "\n",
       "              7         8         9  ...        21        22        23  \\\n",
       "0     -0.126982  0.037647 -0.064911  ... -0.093300 -0.030247  0.125862   \n",
       "1     -0.139326 -0.024676 -0.038572  ...  0.012400 -0.029055  0.068315   \n",
       "2     -0.153539 -0.021744 -0.032416  ... -0.144041  0.039883  0.146865   \n",
       "3     -0.196522 -0.041214 -0.055622  ... -0.050068  0.019684  0.018286   \n",
       "4     -0.178635  0.011020 -0.070727  ... -0.137437  0.000491  0.095065   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "84995 -0.164228 -0.042417 -0.022502  ...  0.025307 -0.020969  0.067957   \n",
       "84996 -0.122340 -0.004241 -0.060150  ... -0.054211  0.055740  0.093475   \n",
       "84997 -0.141780 -0.035653 -0.068010  ... -0.035877 -0.030915  0.112982   \n",
       "84998 -0.115086 -0.062757 -0.078121  ... -0.079448  0.002127  0.111139   \n",
       "84999 -0.148051 -0.089153 -0.073449  ... -0.090129  0.077935  0.024563   \n",
       "\n",
       "             24        25        26        27        28        29  Class  \n",
       "0     -0.075998 -0.203211 -0.113421 -0.032202 -0.199925 -0.137983      1  \n",
       "1     -0.035170 -0.226974 -0.050105 -0.078412 -0.180631 -0.066747      1  \n",
       "2     -0.086697 -0.240962 -0.144000 -0.091510 -0.206072 -0.155127      1  \n",
       "3      0.022157 -0.161324 -0.015622 -0.043951 -0.208535 -0.073233      1  \n",
       "4     -0.012209 -0.176238 -0.080777 -0.105282 -0.187900 -0.072092      1  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "84995 -0.037829 -0.259302 -0.084166 -0.045353 -0.170909 -0.087426      1  \n",
       "84996 -0.059595 -0.205103 -0.044279 -0.103343 -0.192009 -0.081781      1  \n",
       "84997 -0.060992 -0.183590 -0.083636  0.007791 -0.193032 -0.072074      1  \n",
       "84998 -0.063026 -0.132691 -0.121015 -0.044246 -0.204784 -0.110402      1  \n",
       "84999 -0.052842 -0.055504  0.019901 -0.081928 -0.214467 -0.013046      1  \n",
       "\n",
       "[85000 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_fraud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['Time','Amount']] = scaler.fit_transform(df[['Time','Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "only_fraud_df.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df,only_fraud_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.124115</td>\n",
       "      <td>-1.599393</td>\n",
       "      <td>-0.149914</td>\n",
       "      <td>2.109682</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>0.595675</td>\n",
       "      <td>0.644721</td>\n",
       "      <td>0.317964</td>\n",
       "      <td>-0.369205</td>\n",
       "      <td>1.019132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249379</td>\n",
       "      <td>0.298205</td>\n",
       "      <td>0.246104</td>\n",
       "      <td>-0.714229</td>\n",
       "      <td>-0.171008</td>\n",
       "      <td>0.274035</td>\n",
       "      <td>-0.646160</td>\n",
       "      <td>-0.378601</td>\n",
       "      <td>-0.306242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.140221</td>\n",
       "      <td>-0.077036</td>\n",
       "      <td>0.114725</td>\n",
       "      <td>-0.068618</td>\n",
       "      <td>0.045462</td>\n",
       "      <td>-0.106829</td>\n",
       "      <td>0.094702</td>\n",
       "      <td>-0.111777</td>\n",
       "      <td>-0.072793</td>\n",
       "      <td>-0.062311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019231</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>0.107842</td>\n",
       "      <td>-0.052991</td>\n",
       "      <td>-0.230395</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>-0.124035</td>\n",
       "      <td>-0.172561</td>\n",
       "      <td>-0.072274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.947813</td>\n",
       "      <td>-3.226223</td>\n",
       "      <td>-3.263305</td>\n",
       "      <td>-1.845165</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-4.396491</td>\n",
       "      <td>1.738821</td>\n",
       "      <td>5.760154</td>\n",
       "      <td>-0.029454</td>\n",
       "      <td>-0.901879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.114422</td>\n",
       "      <td>3.552622</td>\n",
       "      <td>-0.124398</td>\n",
       "      <td>0.141898</td>\n",
       "      <td>0.793311</td>\n",
       "      <td>-0.359761</td>\n",
       "      <td>0.257221</td>\n",
       "      <td>5.835037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521871</td>\n",
       "      <td>1.874811</td>\n",
       "      <td>-0.451824</td>\n",
       "      <td>-1.223864</td>\n",
       "      <td>0.202895</td>\n",
       "      <td>0.597169</td>\n",
       "      <td>1.184379</td>\n",
       "      <td>-0.439232</td>\n",
       "      <td>0.323480</td>\n",
       "      <td>0.519073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433782</td>\n",
       "      <td>1.543418</td>\n",
       "      <td>-0.054433</td>\n",
       "      <td>-1.532265</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>0.728989</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>-0.084599</td>\n",
       "      <td>-0.256801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.136310</td>\n",
       "      <td>-1.142740</td>\n",
       "      <td>1.468732</td>\n",
       "      <td>0.241103</td>\n",
       "      <td>0.625281</td>\n",
       "      <td>0.338581</td>\n",
       "      <td>0.776647</td>\n",
       "      <td>-0.039810</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>-0.265041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.369480</td>\n",
       "      <td>-0.235014</td>\n",
       "      <td>-1.353952</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>-0.087556</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>-0.319940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368721</th>\n",
       "      <td>1.360712</td>\n",
       "      <td>0.149260</td>\n",
       "      <td>0.988698</td>\n",
       "      <td>-0.605170</td>\n",
       "      <td>-0.788264</td>\n",
       "      <td>1.238822</td>\n",
       "      <td>-0.203064</td>\n",
       "      <td>0.861209</td>\n",
       "      <td>0.067349</td>\n",
       "      <td>-0.279204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326673</td>\n",
       "      <td>-0.816542</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>-0.010456</td>\n",
       "      <td>-0.377837</td>\n",
       "      <td>0.128193</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.068558</td>\n",
       "      <td>-0.349773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368722</th>\n",
       "      <td>-0.144409</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.148645</td>\n",
       "      <td>-0.104169</td>\n",
       "      <td>0.046285</td>\n",
       "      <td>-0.127849</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>-0.101806</td>\n",
       "      <td>-0.062445</td>\n",
       "      <td>-0.060322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030523</td>\n",
       "      <td>-0.052311</td>\n",
       "      <td>0.109520</td>\n",
       "      <td>-0.045674</td>\n",
       "      <td>-0.214116</td>\n",
       "      <td>-0.088019</td>\n",
       "      <td>-0.053956</td>\n",
       "      <td>-0.185627</td>\n",
       "      <td>-0.087897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368723</th>\n",
       "      <td>-0.312295</td>\n",
       "      <td>1.259310</td>\n",
       "      <td>-0.049484</td>\n",
       "      <td>-0.721776</td>\n",
       "      <td>0.071903</td>\n",
       "      <td>1.864771</td>\n",
       "      <td>3.635628</td>\n",
       "      <td>-0.821682</td>\n",
       "      <td>0.929256</td>\n",
       "      <td>0.128685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070189</td>\n",
       "      <td>0.104264</td>\n",
       "      <td>-0.107993</td>\n",
       "      <td>1.004823</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>-0.275199</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>0.025074</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368724</th>\n",
       "      <td>-0.132160</td>\n",
       "      <td>1.982903</td>\n",
       "      <td>-0.134427</td>\n",
       "      <td>-1.161183</td>\n",
       "      <td>0.472515</td>\n",
       "      <td>-0.043755</td>\n",
       "      <td>-1.080473</td>\n",
       "      <td>0.306983</td>\n",
       "      <td>-0.373167</td>\n",
       "      <td>0.454594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212230</td>\n",
       "      <td>-0.472417</td>\n",
       "      <td>0.248672</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>-0.195097</td>\n",
       "      <td>0.272711</td>\n",
       "      <td>-0.071660</td>\n",
       "      <td>-0.055715</td>\n",
       "      <td>-0.195658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368725</th>\n",
       "      <td>-0.384429</td>\n",
       "      <td>-0.465150</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>1.326391</td>\n",
       "      <td>-1.345201</td>\n",
       "      <td>0.584115</td>\n",
       "      <td>-0.683284</td>\n",
       "      <td>0.856022</td>\n",
       "      <td>-0.178265</td>\n",
       "      <td>-0.537311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235506</td>\n",
       "      <td>-0.719605</td>\n",
       "      <td>-0.290143</td>\n",
       "      <td>-0.387924</td>\n",
       "      <td>0.413861</td>\n",
       "      <td>0.813386</td>\n",
       "      <td>-0.130873</td>\n",
       "      <td>-0.047641</td>\n",
       "      <td>-0.353327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368726 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      -1.124115 -1.599393 -0.149914  2.109682  0.038543  0.595675  0.644721   \n",
       "1      -0.140221 -0.077036  0.114725 -0.068618  0.045462 -0.106829  0.094702   \n",
       "2      -0.947813 -3.226223 -3.263305 -1.845165  0.003520 -4.396491  1.738821   \n",
       "3       0.521871  1.874811 -0.451824 -1.223864  0.202895  0.597169  1.184379   \n",
       "4      -1.136310 -1.142740  1.468732  0.241103  0.625281  0.338581  0.776647   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "368721  1.360712  0.149260  0.988698 -0.605170 -0.788264  1.238822 -0.203064   \n",
       "368722 -0.144409 -0.056656  0.148645 -0.104169  0.046285 -0.127849 -0.003682   \n",
       "368723 -0.312295  1.259310 -0.049484 -0.721776  0.071903  1.864771  3.635628   \n",
       "368724 -0.132160  1.982903 -0.134427 -1.161183  0.472515 -0.043755 -1.080473   \n",
       "368725 -0.384429 -0.465150  0.818433  1.326391 -1.345201  0.584115 -0.683284   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0       0.317964 -0.369205  1.019132  ... -0.249379  0.298205  0.246104   \n",
       "1      -0.111777 -0.072793 -0.062311  ... -0.019231 -0.002653  0.107842   \n",
       "2       5.760154 -0.029454 -0.901879  ...  0.983785  0.114422  3.552622   \n",
       "3      -0.439232  0.323480  0.519073  ...  0.433782  1.543418 -0.054433   \n",
       "4      -0.039810  0.842324 -0.265041  ...  0.089044  0.369480 -0.235014   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "368721  0.861209  0.067349 -0.279204  ... -0.326673 -0.816542  0.008957   \n",
       "368722 -0.101806 -0.062445 -0.060322  ...  0.030523 -0.052311  0.109520   \n",
       "368723 -0.821682  0.929256  0.128685  ...  0.070189  0.104264 -0.107993   \n",
       "368724  0.306983 -0.373167  0.454594  ... -0.212230 -0.472417  0.248672   \n",
       "368725  0.856022 -0.178265 -0.537311  ... -0.235506 -0.719605 -0.290143   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "0      -0.714229 -0.171008  0.274035 -0.646160 -0.378601 -0.306242      0  \n",
       "1      -0.052991 -0.230395 -0.069105 -0.124035 -0.172561 -0.072274      1  \n",
       "2      -0.124398  0.141898  0.793311 -0.359761  0.257221  5.835037      0  \n",
       "3      -1.532265 -0.004131  0.728989  0.002979 -0.084599 -0.256801      0  \n",
       "4      -1.353952  0.013564 -0.087556  0.501524  0.251930 -0.319940      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "368721 -0.010456 -0.377837  0.128193  0.219217  0.068558 -0.349773      0  \n",
       "368722 -0.045674 -0.214116 -0.088019 -0.053956 -0.185627 -0.087897      1  \n",
       "368723  1.004823  0.674600 -0.275199  0.045933  0.025074 -0.335356      0  \n",
       "368724  0.025584 -0.195097  0.272711 -0.071660 -0.055715 -0.195658      0  \n",
       "368725 -0.387924  0.413861  0.813386 -0.130873 -0.047641 -0.353327      0  \n",
       "\n",
       "[368726 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exported Generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('D:/Uni Docs/DSC4996/Dynamic_fraud_detection_system/Data/generated_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
